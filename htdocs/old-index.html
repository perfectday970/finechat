<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <title>Ollama Chat – Text & Sprache, mit gesperrtem Eingabefeld für erkannten Text</title>
  <style>
    body { font-family: sans-serif; }
    .chatbox {
      width: 50%;
      height: 300px;
      border: 1px solid #ccc;
      overflow-y: auto;
      padding: 10px;
      margin-bottom: 20px;
    }
    .user { color: blue; font-weight: bold; }
    .assistant { color: darkgreen; font-weight: bold; }
  </style>
</head>
<body>
<h1>Ollama Chat (Manuelles Tippen & Spracheingabe)</h1>

<div id="chatbox" class="chatbox"></div>

<!-- Eingabefeld + Buttons -->
<input type="text" id="user_input" style="width:300px;" placeholder="Hier tippen ...">
<button type="button" onclick="sendManual()">Senden</button>
<button type="button" id="toggleBtn" onclick="toggleListening()">Spracheingabe starten</button>
<button type="button" onclick="cancelTTS()">X</button>
<br>
<select id="ttsMode">
  <option value="browser">Browser TTS</option>
  <option value="coqui">Coqui TTS</option>
</select>
<label for="aiModel">KI-Modell wählen:</label>
<select id="aiModel">
  <option value="deepseek">DeepSeek</option>
  <option value="ollama">Llama (Ollama)</option>
</select>

<script>
// ------------------ GLOBALE VARIABLEN ------------------
let recognition;              // Instanz der Web Speech API
let isListening = false;      // Merker für ein/aus
let finalTranscript = "";     // hier sammeln wir erkannte Endergebnisse
let lastSpeechTime = 0;       // Zeitstempel letztes onresult
let checkTimer;               // setInterval ID
let userInput = document.getElementById("user_input");
let isTTSRunning = false;


// ------------------ SESSION / SERVER ------------------
// Wir nehmen an, dass du am Server ein ollama_chat_api.py hast, das JSON zurückgibt.
// (Anpassen, wenn dein Pfad anders ist)
let sessionId = "";

// ------------------ TOGGLE-FUNKTION ------------------
function toggleListening() {
  if (isTTSRunning) {
    console.log("Mikrofonsteuerung deaktiviert, da Sprachausgabe läuft.");
    return;
  }

  if (!isListening) {
    // Start
    isListening = true;
    document.getElementById("toggleBtn").textContent = "Mikrofon ausschalten";
    startContinuousRecognition();
  } else {
    // Stop
    isListening = false;
    document.getElementById("toggleBtn").textContent = "Mikrofon einschalten";
    stopContinuousRecognition();
    userInput.disabled = false;
  }
}

// ------------------ START/STOP ERKENNUNG ------------------
function startContinuousRecognition() {
  recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = "de-DE";
  recognition.interimResults = false;
  recognition.continuous = true;

  recognition.onstart = function() {
    console.log("Spracherkennung gestartet");
    finalTranscript = "";
    lastSpeechTime = Date.now();
    // Jede Sekunde checken, ob >=3s Pause
    checkTimer = setInterval(checkSilence, 200);
  };

  recognition.onresult = function(event) {
    console.log("Es wurde eine Spracheingabe verstanden");
   //  let interimTranscript = "";
     for (let i = event.resultIndex; i < event.results.length; i++) {

        if (!isTTSRunning) {
            let result = event.results[i];
            if(result.isFinal)
            {
              console.log(" TTS läuft nicht. " + finalTranscript);

            //     let chunk = result[0].transcript.toLowerCase().trim();
              finalTranscript += result[0].transcript + " ";

              userInput.value = finalTranscript.trim();
              userInput.disabled = true;
            }
            lastSpeechTime = Date.now();
        }
        /*
        else if (isTTSRunning)
        {
            let result = event.results[i];
            if (result.isFinal) {
              finalTranscript += result[0].transcript + " ";
              console.log("TTS läuft gerade. "+finalTranscript);
              let recognizedText = (finalTranscript)
                   .trim()
                   .toLowerCase();
              if (recognizedText.includes("aximo stop") ||
                   recognizedText.includes("aximo hör auf") ||
                   recognizedText.includes("aximo halt")) {
                   cancelTTS();
                   console.log("Stop-Befehl erkannt, TTS abgebrochen.");
              }
            }
           finalTranscript = "";

        }*/
     }
  };

  recognition.onend = function() {
    console.log("Spracherkennung endete – neu starten, falls toggle noch an");
    clearInterval(checkTimer);
    // Chrome beendet manchmal trotz continuous = true
    // => Also neu starten, wenn isListening
    if (isListening) {
      recognition.start();
    }
  };
  recognition.start();
}

function stopContinuousRecognition() {
  if (recognition) {
    recognition.onend = null;  // nicht wieder neu starten
    recognition.stop();
    recognition = null;
    clearInterval(checkTimer);
  }
}

// ------------------ AUTO-SEND NACH 3S PAUSE ------------------
function checkSilence() {
  let diff = Date.now() - lastSpeechTime;
  // Nach 3s ohne neue Erkennung => abschicken, wenn finalTranscript nicht leer ist
  if (diff >= 200 && finalTranscript.trim() !== "") {
    let text = finalTranscript.trim();
    finalTranscript = "";
    sendMessageToServer(text);
    // Eingabefeld leeren + freigeben
    userInput.value = "";
    userInput.disabled = false;
  }
}

// ------------------ MANUELLES SENDEN ------------------
function sendManual() {
  // Nur senden, wenn Feld nicht leer
  let text = userInput.value.trim();
  if (text === "") return;

  sendMessageToServer(text);

  // Feld leeren + freigeben
  userInput.value = "";
  userInput.disabled = false;
}

function getAPIEndpoint() {
  let aiModel = document.getElementById("aiModel").value;
  if (aiModel === "deepseek") {
    return "http://localhost:5000/generate";  // Flask-Server für DeepSeek
  } else {
    return "/cgi-bin/ollama_chat_api.py";  // Ollama Chat API
  }
}

// ------------------ SERVER-AUFUFR (AJAX) ------------------
function sendMessageToServer(text) {
  console.log("Sende an Server:", text);
  let apiUrl = getAPIEndpoint();  // Wählt den richtigen API-Endpunkt

  let formData = new FormData();
  formData.append("session_id", sessionId);
  formData.append("user_input", text);
  if (!apiUrl.includes("localhost:5000")) {
    fetch(apiUrl, {
      method: "POST",
      body: formData
    })
            .then(response => response.json())
            .then(data => {
              sessionId = data.session_id;
              renderChat(data.chat);
              // Letzten Assistant-Post vorlesen, falls vorhanden
              let lastMsg = data.chat[data.chat.length - 1];
              if (lastMsg && lastMsg.role === "assistant") {
                speakResponse(lastMsg.content);
              }
            })
            .catch(err => console.error("Fehler beim Fetch:", err));
  }else{
      // Llama/Ollama: JSON-Antwort erwarten
    fetch(apiUrl, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        session_id: sessionId,
        text: text  // `user_input` durch `text` ersetzen, um mit Flask übereinzustimmen
      })
    })
            .then(response => response.json())
            .then(data => {
             // sessionId = data.session_id;
             // renderChat(data.chat);
              // Letzten Assistant-Post vorlesen, falls vorhanden
            //  let lastMsg = data.chat[data.chat.length - 1];
            //  if (lastMsg && lastMsg.role === "assistant") {
                speakResponse(data.response);
            //  }
            })
            .catch(err => console.error("Fehler beim Fetch:", err));
  }
}

// ------------------ CHAT DARSTELLEN ------------------
function renderChat(chatArray) {
  const chatbox = document.getElementById("chatbox");
  chatbox.innerHTML = "";
  chatArray.forEach(msg => {
    let p = document.createElement("p");
    if (msg.role === "user") {
      p.innerHTML = "<span class='user'>Du:</span> " + msg.content;
    } else {
      p.innerHTML = "<span class='assistant'>Ollama:</span> " + msg.content;
    }
    chatbox.appendChild(p);
  });
  chatbox.scrollTop = chatbox.scrollHeight;
}

// ------------------ TTS FÜR OLLAMA-ANTWORT ------------------
let currentUtterance = null; // global

function speakResponse(text) {
    // Den TTS-Modus aus dem <select> abfragen
  let mode = document.getElementById("ttsMode").value;

  if (mode === "browser") {
      // Falls noch eine alte Sprachausgabe läuft, abbrechen
      if (currentUtterance) {
        speechSynthesis.cancel();
      }

      currentUtterance = new SpeechSynthesisUtterance(text);
      currentUtterance.lang = "de-DE";

      currentUtterance.onstart = function() {
        isTTSRunning = true;
        console.log("TTS hat begonnen.");
        isListening = false;
        document.getElementById("toggleBtn").disabled = true;
        document.getElementById("toggleBtn").textContent = "Sprachausgabe läuft gerade";
        stopContinuousRecognition();
        userInput.disabled = false;
      };
      currentUtterance.onend = function() {
        isTTSRunning = false;
        currentUtterance = null;
        console.log("TTS ist fertig.");
        isListening = true;
        document.getElementById("toggleBtn").disabled = false;
        document.getElementById("toggleBtn").textContent = "Mikrofon ausschalten";
        startContinuousRecognition();
      };

      window.speechSynthesis.speak(currentUtterance);
    } else {
        // 2) Coqui TTS -> wir holen vom Server ein WAV und spielen es ab
      fetchCoquiTTSAndPlay(text);
  }
}

function cancelTTS() {
  if (currentUtterance) {
    speechSynthesis.cancel(); // Abbrechen
    currentUtterance = null;
  }
  finalTranscript = "";
  isTTSRunning = false;
  console.log("TTS manuell abgebrochen!");
}

function fetchCoquiTTSAndPlay(text) {
  console.log("Hole Coqui TTS Audio für:", text);
  // POST an /cgi-bin/coqui_tts_api.py
  let formData = new FormData();
  formData.append("text", text);

// fetch("/cgi-bin/coqui_tts_api.py", {
  fetch("http://localhost:5000/synthesize", {
    method: "POST",
    body: formData
  })
  .then(response => {
    if (!response.ok) {
      throw new Error("Fehler beim Holen der WAV: " + response.statusText);
    }
    return response.blob(); // Audio als blob
  })
  .then(blob => {
    // In Audio abspielen
    let audioUrl = URL.createObjectURL(blob);
    let audio = new Audio(audioUrl);
    audio.onplay = function() {
        console.log("Coqui TTS startet.");
        isTTSRunning = true;
        stopContinuousRecognition(); // Mikrofon deaktivieren
        document.getElementById("toggleBtn").disabled = true;
        document.getElementById("toggleBtn").textContent = "Sprachausgabe läuft gerade";
    };

    audio.onended = function() {
        console.log("Coqui TTS beendet.");
        isTTSRunning = false;
        startContinuousRecognition(); // Mikrofon wieder aktivieren
        document.getElementById("toggleBtn").disabled = false;
        document.getElementById("toggleBtn").textContent = "Mikrofon ausschalten";
    };
    audio.play().catch(err => console.error("Fehler beim Abspielen von Coqui TTS Audio:", err));

  })
  .catch(err => {
    console.error("Fehler Coqui TTS:", err);
  });
}

</script>
</body>
</html>
